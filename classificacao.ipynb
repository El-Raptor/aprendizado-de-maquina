{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Nome - RGA:\n",
    "    Fábio Holanda Saraiva Júnior - 2015.1905.006-2\n",
    "    Felipe Salles Lopez - 2016.1907.032-4\n",
    "    Lucas Avanzi - 2016.1907.024-3\n",
    "    Lucas Antonio dos Santos - 2016.1907.013-8\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn import model_selection\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import warnings\n",
    "\n",
    "#evitar poluição visual\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "dataset_path = [\n",
    "                \"./datasets/hayes-roth/hayes-roth.data\",\n",
    "                \"./datasets/balance-scale/balance-scale.data\",\n",
    "                \"./datasets/blood-transfusion/transfusion.data\",\n",
    "                \"./datasets/wine/wine.data\",\n",
    "                \"./datasets/glass/glass.data\",\n",
    "                \"./datasets/haberman/haberman.data\",\n",
    "                \"./datasets/zoo/zoo.CSV\",\n",
    "                \"./datasets/iris/iris.data\",\n",
    "                \"./datasets/lymphography/lymphography.data\",\n",
    "                \"./datasets/tae/tae.data\"\n",
    "                ]\n",
    "\n",
    "#indice da linha onde os exemplos são iniciados\n",
    "#utilizado na leitura do dataset\n",
    "first_class_line = [\n",
    "    0,\n",
    "    0,\n",
    "    1,\n",
    "    0,\n",
    "    0,\n",
    "    0,\n",
    "    0,\n",
    "    0,\n",
    "    0,\n",
    "    0\n",
    "]\n",
    "\n",
    "#coluna onde a classe é representada para cada dataset\n",
    "#utilizado na separação da classe do atributo\n",
    "class_index = [\n",
    "    5,\n",
    "    0,\n",
    "    4,\n",
    "    0,\n",
    "    10,\n",
    "    3,\n",
    "    17,\n",
    "    4,\n",
    "    0,\n",
    "    5\n",
    "]\n",
    "\n",
    "\n",
    "#representa o tipo(numerico/string) da classe\n",
    "type_of_class = [\n",
    "    0,\n",
    "    1,\n",
    "    0,\n",
    "    0,\n",
    "    0,\n",
    "    0,\n",
    "    0,\n",
    "    1,\n",
    "    0,\n",
    "    0  \n",
    "]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recebe um array contendo todo o dataset\n",
    "# Retorna dois arrays, um contendo somente os atributos das instancias, o outro contendo as classes das instancias\n",
    "def separate_class_of_parameters(np_array, index_of_class):\n",
    "    # onde a classe é a primeira coluna no dataset\n",
    "    if index_of_class == 0:\n",
    "        return np_array[:, 1:], np_array[:, 0]\n",
    "        \n",
    "    #onde a classe é a ultima coluna do dataset\n",
    "    else:\n",
    "        return np_array[:, 0:index_of_class], np_array[:, index_of_class]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def classification(i):\n",
    "    #Verificar inicio do dataset\n",
    "    \n",
    "    if first_class_line[i] == 0:\n",
    "        pd_dataset = pd.read_csv(dataset_path[i], header = None)\n",
    "        \n",
    "    else:\n",
    "        pd_dataset = pd.read_csv(dataset_path[i])\n",
    "    \n",
    "    \n",
    "    array = np.array(pd_dataset)\n",
    "\n",
    "\n",
    "    data, target = separate_class_of_parameters(array, class_index[i])\n",
    "\n",
    "    #print(data)\n",
    "    #print(target)\n",
    "    \n",
    "    \n",
    "\n",
    "    inner_kf = model_selection.StratifiedKFold(n_splits=10, shuffle=True, random_state=None) #treinamento dos algoritmos\n",
    "    outer_kf = model_selection.StratifiedKFold(n_splits=3, shuffle=True, random_state=None) #ajuste dos parâmetros\n",
    "\n",
    "\n",
    "\n",
    "    print(\"====== Started Decision Tree parameters tuning\")\n",
    "\n",
    "    decision_tree = tree.DecisionTreeClassifier()\n",
    "    param_dist = {'max_depth':[3,4,5,6,7,8,9,10]}\n",
    "    grid_search = GridSearchCV(decision_tree, param_grid=param_dist, cv=outer_kf, scoring='accuracy', refit=False)\n",
    "    grid_search.fit(data, target)\n",
    "    decisionTreeBestParams = grid_search.best_params_\n",
    "    print(\"Decision Tree: %s \\n\\n\" % decisionTreeBestParams)\n",
    "\n",
    "\n",
    "    print(\"====== Started KNN parameters tuning\")\n",
    "\n",
    "    knn = KNeighborsClassifier()\n",
    "    param_dist = {'n_neighbors': list(np.arange(1, 15)), 'metric':['euclidean'], 'weights':['uniform', 'distance']} #Parâmetros testados\n",
    "    grid_search = GridSearchCV(knn, param_grid=param_dist, cv=outer_kf, scoring='accuracy', refit=False)\n",
    "    grid_search.fit(data, target)\n",
    "    knnBestParams = grid_search.best_params_\n",
    "    print(\"KNN: %s \\n\\n\" % knnBestParams)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    print(\"====== Started Naive Bayes parameters tuning\")\n",
    "\n",
    "    naive_bayes = GaussianNB()\n",
    "    param_dist = {'var_smoothing': [1e-6, 1e-7, 1e-8,1e-9, 1e-10]}\n",
    "    grid_search = GridSearchCV(naive_bayes, param_grid=param_dist, cv=outer_kf, scoring='accuracy', refit=False)\n",
    "    grid_search.fit(data, target)\n",
    "    decisionNaiveBayesBestParams = grid_search.best_params_\n",
    "    print(\"Decision Naive Bayes: %s \\n\\n\" % decisionNaiveBayesBestParams)\n",
    "\n",
    "\n",
    "\n",
    "    print(\"====== Started Logistic Regression parameters tuning\")\n",
    "\n",
    "    reg_log = LogisticRegression(random_state=0)\n",
    "    param_dist = {'random_state':[0], 'tol' : [1e-4,1e-5, 1e-5, 1e-6]}\n",
    "    grid_search = GridSearchCV(reg_log, param_grid=param_dist, cv=outer_kf, scoring='accuracy', refit=False)\n",
    "    grid_search.fit(data, target)\n",
    "    decisionLogisticRegressionBestParams = grid_search.best_params_\n",
    "    print(\"Decision Logistic Regression: %s \\n\\n\" % decisionLogisticRegressionBestParams)\n",
    "\n",
    "\n",
    "\n",
    "    print(\"====== Started MLP parameters tuning\")\n",
    "\n",
    "    mlp = MLPClassifier()\n",
    "    param_dist = {'hidden_layer_sizes' : [(12,),(20,),(30,)], 'activation' : [\"logistic\"], 'max_iter' : [100], \n",
    "                  'alpha' : [0.01], 'solver' : [\"sgd\"], 'tol' : [1e-9], 'learning_rate_init' : [.01], 'verbose' : [False]} \n",
    "    grid_search = GridSearchCV(mlp, param_grid=param_dist, cv=outer_kf, scoring='accuracy', refit=False)\n",
    "    grid_search.fit(data, target)\n",
    "    mlpBestParams = grid_search.best_params_\n",
    "    print(\"Decision MLP: %s \\n\\n\" % mlpBestParams)\n",
    "\n",
    "\n",
    "\n",
    "    #Pala descrição adicionar:\n",
    "    #Deve-se reportar o desempenho de cada algoritmo com cada combinação de parâmetro\n",
    "\n",
    "\n",
    "    decision_tree = tree.DecisionTreeClassifier(**decisionTreeBestParams)\n",
    "    knn = KNeighborsClassifier(**knnBestParams)\n",
    "    naive_bayes = GaussianNB(**decisionNaiveBayesBestParams)\n",
    "    reg_log = LogisticRegression(**decisionLogisticRegressionBestParams)\n",
    "    mlp = MLPClassifier(**mlpBestParams)\n",
    "\n",
    "    predicted_classes = dict()\n",
    "    if type_of_class[i] == 0:\n",
    "        predicted_classes['tree'] = np.zeros(len(data))\n",
    "        predicted_classes['knn'] = np.zeros(len(data))\n",
    "        predicted_classes['naive'] = np.zeros(len(data))\n",
    "        predicted_classes['reg_log'] = np.zeros(len(data)) \n",
    "        predicted_classes['mlp'] = np.zeros(len(data))\n",
    "\n",
    "    else:\n",
    "        predicted_classes['tree'] = np.empty(len(data), dtype = object)\n",
    "        predicted_classes['knn'] = np.empty(len(data), dtype =object)\n",
    "        predicted_classes['naive'] = np.empty(len(data), dtype = object)\n",
    "        predicted_classes['reg_log'] = np.empty(len(data), dtype = object) \n",
    "        predicted_classes['mlp'] = np.empty(len(data), dtype = object)\n",
    "\n",
    "    for train,test in inner_kf.split(data, target): # TEST: 10, 20, 30, 40 ...\n",
    "        data_train, target_train = data[train], target[train]\n",
    "        data_test, target_test = data[test], target[test]\n",
    "\n",
    "        decision_tree = decision_tree.fit(data_train, target_train)   \n",
    "        decision_tree_predicted = decision_tree.predict(data_test)\n",
    "        predicted_classes['tree'][test] = decision_tree_predicted\n",
    "\n",
    "        knn = knn.fit(data_train, target_train)\n",
    "        knn_predicted = knn.predict(data_test)\n",
    "        predicted_classes['knn'][test] = knn_predicted\n",
    "\n",
    "        naive_bayes = naive_bayes.fit(data_train, target_train)\n",
    "        naive_predicted = naive_bayes.predict(data_test)\n",
    "        predicted_classes['naive'][test] = naive_predicted\n",
    "\n",
    "        reg_log = reg_log.fit(data_train, target_train)\n",
    "        reg_log_predicted = reg_log.predict(data_test)\n",
    "        predicted_classes['reg_log'][test] = reg_log_predicted\n",
    "\n",
    "        mlp = mlp.fit (data_train, target_train)\n",
    "        mlp_predicted = mlp.predict(data_test)\n",
    "        predicted_classes['mlp'][test] = mlp_predicted\n",
    "\n",
    "    for classifier in predicted_classes.keys():\n",
    "        print(\"======================================================================\")\n",
    "        print(\"Resultados do classificador %s\\n%s\\n\" \n",
    "              %(classifier, metrics.classification_report(target, predicted_classes[classifier])))\n",
    "        print(\"Matriz de confusão: \\n%s\\n\\n\\n\" % metrics.confusion_matrix(target, predicted_classes[classifier]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== Started Decision Tree parameters tuning\n",
      "Decision Tree: {'max_depth': 8} \n",
      "\n",
      "\n",
      "====== Started KNN parameters tuning\n",
      "KNN: {'metric': 'euclidean', 'n_neighbors': 11, 'weights': 'distance'} \n",
      "\n",
      "\n",
      "====== Started Naive Bayes parameters tuning\n",
      "Decision Naive Bayes: {'var_smoothing': 1e-06} \n",
      "\n",
      "\n",
      "====== Started Logistic Regression parameters tuning\n",
      "Decision Logistic Regression: {'random_state': 0, 'tol': 0.0001} \n",
      "\n",
      "\n",
      "====== Started MLP parameters tuning\n",
      "Decision MLP: {'activation': 'logistic', 'alpha': 0.01, 'hidden_layer_sizes': (30,), 'learning_rate_init': 0.01, 'max_iter': 100, 'solver': 'sgd', 'tol': 1e-09, 'verbose': False} \n",
      "\n",
      "\n",
      "======================================================================\n",
      "Resultados do classificador tree\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.55      0.52        49\n",
      "           2       0.58      0.58      0.58        50\n",
      "           3       0.70      0.63      0.67        52\n",
      "\n",
      "    accuracy                           0.59       151\n",
      "   macro avg       0.59      0.59      0.59       151\n",
      "weighted avg       0.60      0.59      0.59       151\n",
      "\n",
      "\n",
      "Matriz de confusão: \n",
      "[[27 13  9]\n",
      " [16 29  5]\n",
      " [11  8 33]]\n",
      "\n",
      "\n",
      "\n",
      "======================================================================\n",
      "Resultados do classificador knn\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.55      0.61        49\n",
      "           2       0.60      0.58      0.59        50\n",
      "           3       0.55      0.67      0.60        52\n",
      "\n",
      "    accuracy                           0.60       151\n",
      "   macro avg       0.61      0.60      0.60       151\n",
      "weighted avg       0.61      0.60      0.60       151\n",
      "\n",
      "\n",
      "Matriz de confusão: \n",
      "[[27  7 15]\n",
      " [ 7 29 14]\n",
      " [ 5 12 35]]\n",
      "\n",
      "\n",
      "\n",
      "======================================================================\n",
      "Resultados do classificador naive\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.51      0.80      0.62        49\n",
      "           2       0.44      0.28      0.34        50\n",
      "           3       0.63      0.52      0.57        52\n",
      "\n",
      "    accuracy                           0.53       151\n",
      "   macro avg       0.53      0.53      0.51       151\n",
      "weighted avg       0.53      0.53      0.51       151\n",
      "\n",
      "\n",
      "Matriz de confusão: \n",
      "[[39  5  5]\n",
      " [25 14 11]\n",
      " [12 13 27]]\n",
      "\n",
      "\n",
      "\n",
      "======================================================================\n",
      "Resultados do classificador reg_log\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.71      0.63        49\n",
      "           2       0.53      0.50      0.52        50\n",
      "           3       0.61      0.48      0.54        52\n",
      "\n",
      "    accuracy                           0.56       151\n",
      "   macro avg       0.57      0.57      0.56       151\n",
      "weighted avg       0.57      0.56      0.56       151\n",
      "\n",
      "\n",
      "Matriz de confusão: \n",
      "[[35  9  5]\n",
      " [14 25 11]\n",
      " [14 13 25]]\n",
      "\n",
      "\n",
      "\n",
      "======================================================================\n",
      "Resultados do classificador mlp\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.39      0.35      0.37        49\n",
      "           2       0.42      0.52      0.46        50\n",
      "           3       0.33      0.29      0.31        52\n",
      "\n",
      "    accuracy                           0.38       151\n",
      "   macro avg       0.38      0.39      0.38       151\n",
      "weighted avg       0.38      0.38      0.38       151\n",
      "\n",
      "\n",
      "Matriz de confusão: \n",
      "[[17 17 15]\n",
      " [ 9 26 15]\n",
      " [18 19 15]]\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classification(9)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
